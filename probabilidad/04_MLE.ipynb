{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE (Estimacion de maxima verosimilitud - Maximum likelihood Estimation)\n",
    "- Es un framework para estimacion de densidades de probabilidad\n",
    "- Permite estimar densidades de probabilidad dentro de un esquema de trabajo muy general\n",
    "\n",
    "**Escoger la distribucion:** Teniendo solo una muestra de los datos\n",
    "\n",
    "**Escoger los parametros de la distribucion:** Que mejor ajustan la distribucion a los datos, \n",
    "\n",
    "**MLE es un problema de optimizacion**\n",
    "\n",
    "$$P(X;\\theta) = L(X;\\theta)$$\n",
    "$$maxL(X;\\theta) → max \\prod_{i}P(X_i;\\theta)$$\n",
    "\n",
    "Al factorizar distribuciones de probabilidad, el producto se hace cada vez mas pequeño, (esto es malo genera underflour) para resolver esto se aplica el logaritmo de las probabilidades.\n",
    "\n",
    "El logaritmo de un producto, es la suma de los logaritmos (Propiedad), convirtiendo el problema de producto a sumas\n",
    "\n",
    "$$max \\space log\\space L(X;\\theta) → max \\sum_{i} \\space log \\space P(X_i;\\theta)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE en Machine Learning\n",
    "- ML consiste en ajustar densidades a datos\n",
    "\n",
    "## Regreseion Lineal con MLE\n",
    "|||\n",
    "|---|---|\n",
    "|$m$ = pendiente|$b_{0}$ = peso|\n",
    "|$b$ = intercepto|$b_{1}$ = bias|\n",
    "\n",
    "Donde\n",
    "$m = b_{0} \\space | \\space b=b_{1}$\n",
    "\n",
    "$$y = mx+b = b_{0}x+b_1$$\n",
    "\n",
    "\n",
    "\n",
    "$h$ = modelo\n",
    "\n",
    "$$P(y|x) → max \\sum_{i} \\space log \\space P(y_{i}|x_{i};h)$$\n",
    "\n",
    "## MLE IGUAL A ERROR REGRESION LINEAL\n",
    "\n",
    "$$P(y|x) → max \\sum_{i} \\space log \\space P(y_{i}|x_{i};h)$$\n",
    "\n",
    "Parametros de la distribucion **m,b**\n",
    "\n",
    "$h = mx+b$  \n",
    "\n",
    "Distribucion\n",
    "\n",
    "$P = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp{\\left[-\\frac{1}{2}\\left(\\frac{X-\\mu}{\\sigma} \\right)^2 \\right]}$\n",
    "\n",
    "### Error o problema de regresion lineal\n",
    "|Datos Experimentales|Valor de la recta |\n",
    "|--|--|\n",
    "|$(x_{i}, y_{i})$|$y=mx+b$|\n",
    "\n",
    "$error = y_{i}-y$\n",
    "\n",
    "$error = y_{i}-(mx_{i}+b)$\n",
    "\n",
    "$error_{min} =\\sum (y_{i}-(mx_{i}+b))^2$\n",
    "\n",
    "\n",
    "### El MLE es equivalente al error\n",
    "**1. $y-\\mu$ equivalente a $y_{i}-(mx_{i}+b)$**\n",
    "\n",
    "$y$ = ruido\n",
    "\n",
    "$\\mu$ = media\n",
    "\n",
    "$max \\biggr\\{ \\sum_{i} \\space log \\space P(y_{i}|x_{i};h) \\biggr\\} =\n",
    "max \\biggr\\{\n",
    "\\sum \\space log\n",
    "\\biggr( \n",
    "    \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp{\\left[-\\frac{1}{2}\\left(\\frac{y_{i}-(mx_{i}+b)}{\\sigma} \\right)^2 \\right]}  \n",
    "    \\biggr)\n",
    "\\biggr\\}\n",
    "$\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "**2.  $log(a+b) = log(a)+log(b)$**\n",
    "\n",
    "$ \n",
    "= max \\biggr\\{\\sum \\space log\n",
    "\\biggr( \n",
    "    \\frac{1}{\\sigma \\sqrt{2 \\pi}}\n",
    "\\biggr)+\n",
    "\\sum \\space log\n",
    "\\biggr( \n",
    "    \\exp{\\left[-\\frac{1}{2}\\left(\\frac{y_{i}-(mx_{i}+b)}{\\sigma} \\right)^2 \\right]}  \n",
    "    \\biggr)\n",
    "\\biggr\\}\n",
    "$\n",
    "\n",
    "Se despresian las constantes\n",
    "$\\frac{1}{\\sigma \\sqrt{2 \\pi}}$\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "**3. $log(e)$ Son funciones inversas, $f^{-1}(f(x))=x$**\n",
    "\n",
    "$ \n",
    "= max \\biggr\\{\\sum \\space -\\frac{1}{2}\n",
    "    \\left(\\frac{y_{i}-(mx_{i}+b)}{\\sigma} \\right)^2\n",
    "\\biggr\\}\n",
    "$\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "**4. El signo menos (-) convierte el max a minimo, ademas se desprecian las constantes**\n",
    "\n",
    "$$\n",
    "= min -\\frac{1}{2\\sigma^2} \\biggr\\{\\sum \\space \n",
    "    \\left(y_{i}-(mx_{i}+b) \\right)^2\n",
    "\\biggr\\}\n",
    "$$\n",
    "\n",
    "$$error_{min} =\\sum (y_{i}-(mx_{i}+b))^2$$\n",
    "\n",
    "\n",
    "\n",
    "**Con esto se demuestra que el problema de regresion lineal (error) es igual a MLE**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
